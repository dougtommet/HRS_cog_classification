# Use of terms 

|**Terms**|**Meaning**|
|:---------------|:-----------------------------------------------------------------------------------------|
|**_Actuarial_** | The first appearance of "actuarial neuropsychological" I can find in Google Scholar is attributable to Anthony et al (1980), but they refer to a history of the approach as described in the literature going back to at least 1954: "The potential advantages of actuarial psychological test interpretation over more vaguely defined clinical methods have been discussed by various authors (Meehl, 1954; Sawyer, 1966; Spitzer & Endicott, 1974;" as per Anthony et al 1980). Meehl used "Actuarial methods" in the context of psychology and psychiatry in 1954. We use "actuarial" [approach, classification, diagnosis, method] to refer to the strategy described by the Jak/Bondi team and recently by Graves et al (2020) to refer to the classification of individuals according diagnostic classes (normal, MCI, dementia) according to rules applied to cognitive test scores and functional measures, and where the effect of sociodemographic characteristics in cognitive test scores is accounted for through statistical adjustment defined in a _robust norms_ group. Amy Jak and Mark Bondi use the term “actuarial diagnosis” to describe a rule-based approach to classifying cognitive impairment based on objective neuropsychological test performance. The “actuarial” qualifier is used to set the method apart from classifications that rely on clinical judgment or consensus diagnosis, and emphasizes the method applies explicit decision rules that can be replicated and automated. This approach improves transparency and reliability, especially in research and population-based settings (Bondi & Jak, 2014, Graves et al. 2020). Graves uses the terms _actuarial neuropsychological criteria_, _actuarial diagnostic methods_, _actuarial diagnostic classification_, and _actuarially-diagnosed_.|
|**_Knownclass_**| A knownclass model is a categorical latent variable modeling approach (e.g., latent class model, mixture model) where class membership is known. A knownclass model is analogous to a _supervised_ learning model, a categorical latent variable model without known classes is analogous to an _unsupervised_ learning model.|
|**Manly-Jones algorithm**|Describes the approach to cognitive classification described in Manly et al (2022). This approach is a so-called **_actuarial_** classification, with that term attributed to Jak and Bondi and their colleagues. It refers to a procedure for classification using an algorithmic approach, a robust norms group, socio-economic adjustment of cognitive indicators, and the notable exclusion of clinical input. Also referred to as the **_HRS/HCAP algorithm_**.|
|**_Mixture model_**|A categorical latent variable modeling approach that includes continuous variables as class indicators. Contrast with a **_latent class model_**, which is a categorical latent variable modeling approach that includes exclusively categorical variables as class indicators.|
|**Robust norms group** and **normative reference group**|These terms are used interchangeably. The terms refer to a set of people who are believed to be free from the cognitive effects of brain injury and disease. These people -- as a group -- define the range of cognitive performance expected in good health. The "good health" or "free from injury or disease" part of the definition is expressed with either **_robust_** or **_normative_**. The "range of cognitive performance expected" part of the definition is expressed with the words **_norms_** or **_reference_**. This implies we could also refer to the healthy group we obtain an estimate of the range of function expected in good health from as the _normative norms_ group. Kidding aside, **_robust norms_** would be the preferred term because injury or disease is a common thing for a person to experience in life and we would not want to label that experience as _abnormal_, which is implied by the label _normative_. In the actuarial approach as implemented in Manly et al (2022), the robust norms group is defined as a subset of the target sample (n = 1787 of the 3496 HRS/HCAP participants were identified as the robust norms group). This subgroup approach has advantages including any period or cohort or selection effects that are active in the target sample also are active for the robust norms subgroup.|
|**_Supervised_** _vs. unsupervised_|Supervised learning is a type of predictive modeling that uses labeled data (the outcome of interest is already known for each case, i.e. predictive modeling). Unsupervised learning uses unlabeled data, where no outcome is specified. The goal is to find patterns or groupings in the data—similar to traditional methods like cluster analysis or exploratory factor analysis. We are proposing to develop a model using supervised methods (the known HRS/HCAP classification) and apply it to the whole of HRS 2016 (and before and beyond).|





# Overall approach 

We will use a **_supervised latent profile model_** trained with known class labels in HRS/HCAP (results of the Manly-Jones algorithm in the N=3,496 sample) to predict cognitive status in the broader HRS cohort (age 65+, n = 9,972). The model preserves the actuarial approach to classification while introducing a parametric latent structure, item-level covariate adjustment, and probabilistic scoring. A cartoon of the approach is show in Figure 1. 


::: {#fig-fig1 layout-align="center" fig-cap="Calibration model - a supervised latent profile model"}
![](excalidraw/PMM-011-Calibration_Model.excalidraw.svg){width="90%"}
:::

where:

|||
|:----|:-----|
|Latent Class (“c”)|Class membership fixed to HRS/HCAP classification during model calibration |
|Latent cognition  | General cognitive performance (GCP), factor-analytic structure, we allow for class membership to be indicated by the mean and variance of the GCP, after limited control for the effect of sociodemographics.|
|Dependent variables |Observed cognitive test scores (e.g., vdlflf1z, vdwdimmz), ADLs, self-report, informant
|Sociodemographic Covariates|Centered and interacted, included only to adjust indicator means and not to directly inform class membership|
|Missing data strategy|In general, missing data is handled analytically. The Jorm being observed only in those without cognitive performance data (and vice versa) indicator may require separate modeling of the Informant data.|

We are building a supervised latent profile model for cognitive classification using:

- **Latent Class Regression** with known class labels (from the HRS/HCAP actuarial classification).
- **Multivariate cognitive and functional data** (profile indicators) to define latent class structure (Normal, MCI, Dementia).
- **Sociodemographic covariates** used not to predict class directly, but to adjust item means and thresholds.

The model is:

- Estimated in HRS/HCAP (with known class labels, n=3,496),
- Applied to Core HRS (with unknown class labels) for classification (n = 9,972),
- Designed to retain the structure and assumptions of actuarial classification, but expressed in a fully parametric latent variable modeling framework.
  
In psychometric terms, our approach can be described as a **_supervised profile mixture model with structured measurement invariance_**. We estimate latent classes using multivariate cognitive and functional profiles (profile mixture model), use known classifications to supervise training (supervised), allow item means and thresholds to vary by sociodemographic covariates (structured measurement invariance).

## Notable features of model 

### Purposeful misspecification.

We do not include, in our initial model, model parameters that allow for estimation of class membership on the basis of sociodemographics. This is a deliberate choice: we want class membership "predicted" only by cognitive, functional, self-report, and informant data. It is true we correct for measurement differences (in the means/thresholds) of individual cognitive indicators according to sociodemographics, but the effect of these covariates in the class variable is blocked at the cognitive performance variable level. This is a misspecification because we know from Manly et al (2022) Table 2 that sociodemographics are associated with membership in MCI and Dementia groups. This misspecification may make our model fit sub-optimal. But, our main goal is to develop a classification model that maintains fidelity to the spirit of the actuarial classification approach, rather that to achieve an optimally fitting model. 

### Covariate effects are fixed parameters estimated in a preliminary model.

A key component of the Jak/Bondi actuarial approach (and as used in Manly et al 2022) is the standardization of cognitive test scores across a set of covariates. In Manly et at (2022) cognitive ability estimates are regressed on age, sex, race, ethnicity, and educational attainment (and their two-way interactions) in a robust norms group. Cognitive impairment is defined using the residual from these regression equations. This is an attempt to operationalize the notion that _cognitive impairment should be lower than expected for the individual_ when classifying persons according to criteria for mild cognitive impairment and dementia. Simply identifying persons with low cognition is not what we are interested in, because (a) cognitive abilities are widely distributed in healthy populations and (b) a definition of impairment that was based on low performance would mix up factors associated with low peak lifetime cognitive performance and those associated with risk, resistance, resilience, or compensation for brain disease and the cognitive consequences or brain disease. For example, the 2018 NIA/AA Research Criteria for MCI state that cognitive performance should be "below expected range for that individual based on all available information. This may be based on clinical judgment and/or on cognitive test performance (which may or may not be based on comparison to normative data with or without adjustments for age, education, occupation, sex, etc.)" and that cognitive performance in MCI is "usually in the impaired/abnormal range based on population norms, but this is not required as long as the performance is below the range expected for that individual."(Jack et al, 2018, Table 3). Jack and his colleagues, in their announcement of the 2018 research framework, do not provide guidance on how to define "below the range expected for the individual". 

The Jak/Bondi actuarial approach -- as used in Manly et al (2022) and elsewhere -- identifies "below the expected range for the individual" using regression adjustment and residuals obtained from a **_robust norms group_**. The definition of cognitive impairment using covariates is handled in data processing step: (a) robust norms group membership is defined, (b) regression models of performance on sociodemographic factors are estimated in the robust norms group, (c) the models and their parameters are used to generate estimates of expected performance given sociodemographic factors for each individual in the target sample, (d) impairment is defined by comparing observed and expected performance in the form of a scaled residual.

::: {#fig-fig2 layout-align="center" fig-cap="Preliminary model for covariate effects estimated in robust norms sample"}
![](excalidraw/PMM-012-Preliminary_Model.excalidraw.svg){width="90%"}
:::

In the proposed model, we do not use a data processing step to adjust cognitive performance indicators, the analytic model uses cognitive performance data as collected and minimally processed (response categories may be collapsed, performance may be normalized or standardized, but covariates are not used in these steps). To account for the dependence of the cognitive performance scores on sociodemographics in the robust norms group, we estimate a preliminary model restricted to the robust norms group and regress the cognitive performance variables on the sociodemographics. From this model we extract the regression coefficients and use them -- as fixed values -- in subsequent models. **_This is functionally equivalent to computing a residual using predicted values derived from parameter estimates from the robust norms group._** The three approaches illustrated below are approximately equivalent. Manly et al (2023) use the third panel approach (with additional scaling corrections, residuals are scaled by a factor of $\left(\sigma\sqrt{1-R^2}\right)^{-1}$, where $\sigma$ is the standard deviation of the cognitive performance variable in the robust norms group, and $R^2$ is the coefficient of determination from the regression model in the robust norms group: the correction factor accounts for "shrinkage" of the predicted value). 

::: {#fig-fig3 layout-align="center" fig-cap="Approaches to constrained regression"}
![](excalidraw/PMM-013-Approaches_to_constrained_regression.excalidraw.svg){width="90%"}
:::

In conclusion, our approach that involves a two-step calibration where covariate effects in the cognitive variables are estimated in the robust norms group, and used as fixed values in a subsequent classification model, is equivalent to using residuals given expected values derived from robust norms group equations as in Manly et al (2022). The omission of the scaling factor is not relevant, because we do not make inferences or classification decisions based on the scale of the cognitive performance indicators.

:::{.callout-note}
Stata users can prove it to themselves:

```
clear
sysuse auto                           // use cars data set
gen robustsample = (rep78>2)          // robust norms sample good repair rating
standardize mpg if robustsample==1    // standardize to mean and sd in robust group
standardize weight if robustsample==1 // get standardize.ado at https://github.com/rnj0nes/Jones-ADO
standardize price                     // standardize in total sample
glm zmpg zweight if robustsample==1   // regression in robust norms group
scalar B0 = _b[_cons]                 // save constant or intercept term
scalar B1 = _b[zweight]               // save slope term
constraint 2 _cons = B0               // define constraints
constraint 3 zweight =  B1
gen pzmpg = B0 + B1*zweight           // linear predictor
gen resid = zmpg-pzmpg                // residual
glm zmpg zweight zprice , constraints(2 3) // constrained regression
glm zmpg zprice , offset(pzmpg)      // linear predictor as offset
glm resid zprice                     // regression of residual
```

R users are in a bind because there is no easy way to constrain parameters in R. The easiest approximate solution is to specify starting values and limit the iterations to 0.
:::

**We don't use residuals because many of the cognitive indicators** (5 of 9 in Figure 1) are categorical indicators. We can't compute residuals for these, given sociodemographic variables, and have them retain their ordinal nature. So, we will have to extract the $9 \times 15 = 135$ regression coefficients for the $\mathbf{K}$ matrix and load them into the Mplus commands.

## Important differences from the Manly-Jones algorithm

**No explicit decision tree.** The proposed model makes classifications analytically, and does not place a decision-tree like logic on the indicators to arrive at a classification. Parameters of the model are estimated (calibrated) to maximize agreement between the analytically-derived class assignments and the observed (knownclass) assignments derived from the Manly-Jones algorithm (aka the HRS/HCAP actuarial algorithm).

**Missing data.** There is no imputation of missing data. Since the entirety of the classification is performed analytically, we rely upon the maximum likelihood and Bayesian parameter estimation procedures that provide unbiased estimates under the assumption that the missing data mechanism conforms to the conditionally missing at random assumption. This approach is superior to a single value imputation strategy, even if the imputations are drawn stochastically. 

**Socio-demographic adjustment occurs at the indicator level** rather than the construct level. The Manly-Jones algorithm applies sociodemographic corrections at the domain level, implicitly assuming these corrections are appropriate for every sub test. Our approach implements these corrections (or their analytic analog) at the individual test level.

## Classification model 

Below is a cartoon of the classification model:

::: {#fig-fig2 layout-align="center" fig-cap="Classification model"}
![](excalidraw/PMM-012-Classification_Model.excalidraw.svg){width="90%"}
:::

When we use this model, either in cross-validation in the derivation sample (n = 3496) or in application to the full HRS 2016 age 65+ sample (n = 9972):

**All parameters are fixed to presumed population values.** These are those estimated in a particular cross-fold estimation for the assessment of classification model reliability, or the full sample estimation for the final analysis. 

**Known class assignment is not included.** The model will be applied to data sets where these assignments are not observed. 

**Prepare a scoring grid.** We will generate a grid of all possible values for the variables included in the model, and run that grid through the classification model. The resulting data set of variable values and class probabilities will be a handy look-up table for exporting the algorithm to other data sets (i.e., HRS data from 2000 to 2022 for a prevalence and incidence paper). This grid will be immense but data storage is cheap. An important consideration for this is numeric data (e.g., z-scores for standardized cognitive indicators) need to be truncated to a reasonable degree of precision in the *Data management step*.

