---
title: "HRS/HCAP Algorithm in HRS Core"
subtitle: ""
author: "Rich Jones, Doug Tommet"
institute: "Original presentation date: 19 Dec 2024"
date: "updated `r Sys.Date()`"
format: 
  revealjs:
    embed-resources: true
    auto-stretch: false
    theme: [league, my.scss]
    slide-number: true
    self-contained: true
editor: source
---



```{r}
source(here::here("R", "001-libraries.R"))
source(here::here("R", "002-folder_paths.R"))

```

## Contents

1.  Goal of project

2.  Analysis plan and progress

3.  Some selected results

4.  Next steps and timeline

## Project Goal

::: {style="font-size: .8em; "}
-   The goal is to determine to what degree the Core data can be used to approximate the HRS/HCAP classification.

-   The procedure will be to classify 2016 HRS/HCAP participants into cognitive impairment categories (normal, mild cognitive impairment, dementia) using [only data from the HRS 2016 Core interview]{style="color:red;"} (i.e., omitting all HRS/HCAP data).

-   This is only one of several possible approaches to cognitive classification of Core participants.
:::

::: aside
::: {style="font-size: .7em; color:red;"}
After forming this goal, we decided to use the same definition of normative reference group as in HRS/HCAP. This uses some non-CORE data, including the MMSE administered in HRS/HCAP, and claims data.
:::
:::

------------------------------------------------------------------------

```{r}
#| fig-cap: "HRS algorithm"
#| label: fig-hrs-algorithm
#| out-height: "600px"
#| out-width: "700px"
knitr::include_graphics(here::here("Figures", "HRS-algorithm_2024-12-19.png"))
```

------------------------------------------------------------------------

#### Links to supporting detailed documents and results

|                                 |                                       |   |
|-------------------------------------------------------------------------|---|
| Statistical analysis plan       | [GDoc](https://docs.google.com/document/d/1Xkcu0EJAROrsFs18XDiz3FPOD-6CjoWEgAtc2gFQtiw/edit?usp=sharing) |
| Detailed analysis results       | [HTML](https://hrshcap.s3.amazonaws.com/HRS_cognition_2024-11-18.html)                                   |
| Mplus output final factor model | [TXT](https://hrshcap.s3.amazonaws.com/model_final_out.txt?content-type=text/plain)                      |

------

## Progress

-   [x] 1. Factor model for general cognition in HRS/Core (in R)

-   [x] 2. Adjustment, standardization and normalization (in R)

-   [x] 3. Equivalent cut point for identifying severe and moderate cognitive impairment to that used in HRS/HCAP algorithm

-   [ ] 4. Operationalize functional impairment in HRS/Core

-   [ ] 5. Run and compare algorithms

-   [ ] 6. Reporting

## Selected results

::: aside
::: {style="font-size: .8em; "}
Note: all results do **NOT** incorporate sampling weights
:::
:::

-----

### Single factor model for HRS/Core cognition

::: columns
::: {.column width="50%"}
```{r}
#| tbl-cap: "Model 2: Fit statistics"
#| label: tbl-model2-fit
model2_h5_path <- here::here("mplus_output", "model2", "model2.h5")

mplush5::mplus.print.model.fit.information(model2_h5_path) %>%
  filter(grepl("RMSEA : E", description) |
         grepl("SRMR", description) |
         grepl("CFI", description) ) %>%
  gt::gt() %>%
  gt::fmt_number(
    columns = value,
    decimals = 3
  ) %>%
  gt::cols_label(
    description = "Fit statistic",
    value = "Value"
  )  %>%
  gt::opt_stylize(6, color="gray") %>%
  gt::tab_options(
    data_row.padding = gt::px(2)
  )

```

```{r}
#| tbl-cap: "Model 2: Factor loadings"
#| label: tbl-model2-loadings
item_df <- tribble(~item, ~label,
"vdori",  "Orientation to time",
"vdlfl1z",  "Animal naming",
"vdlfl2",  "Scissors & cactus",
"vdlfl3",  "President & vice-president",
"vdcount", "Count backwards from 20",
"vdsevens", "Serial sevens",
"vdwdimmz", "Immediate word recall",
"vdwddelz", "Delayed word recall",
"vdexf7z", "Number series"
)

mplush5::mplus.print.standardized.model.results(model2_h5_path, "stdyx") %>%
  filter(grepl("F BY", Statement))  %>%
  separate(Statement, into = c("f", "by", "item"), sep = " ") %>%
  mutate(item = str_to_lower(item)) %>%
  left_join(item_df, by = c("item" = "item")) %>%
  select(item, label, Estimate) %>%
  gt::gt() %>%
  gt::fmt_number(
    columns = Estimate,
    decimals = 3
  ) %>%
  gt::cols_label(
    item = "Item",
    label = "Label",
    Estimate = "Std Factor Loading"
  ) %>%
  gt::opt_stylize(6, color="gray") %>%
  gt::tab_options(
    data_row.padding = gt::px(2)
  )

```

::: {style="font-size: .5em; "}
Note: items with a “z” at the end are continuous indicators, the others are categorical indicators.
:::
:::

::: {.column width="50%"}
::: {style="font-size: .7em; "}
-   The single factor model fits well by conventional fit criteria.

-   Like the HRS/HCAP factor models, we **do not include** immediate memory performance in the model.

-   We **do include** naming and serial 7s, which are not in HRS/HCAP models

-   [*During the meeting we discussed that the model may be too heavy in "other" (notably serial 7s, number series) and less "memory" and this may be problematic for AD. We will explore other solutions.*]{style="color:red;"}
:::
:::
:::
------------------------------------------------------------------------


```{r}
#| fig-cap: Distribution of factor scores by HCAP normative reference status
#| label: fig-hist-factor-scores-hcap
#| out-width: 600px
#| out-height: 500px
hrs16_cog <- readRDS(fs::path(r_objects_folder, "020_hrs16_cog.rds"))

F_mean <- hrs16_cog %>%
  filter(!is.na(normexcld)) %>%
  mutate(normexcld_f = factor(normexcld, labels = c("HCAP - Included sample", "HCAP - Excluded sample"))) %>%
  group_by(normexcld_f) %>%
  summarize(mean = mean(F, na.rm=TRUE))

dat_text <- tibble(
  label = c("In the 'normative' \n reference group", "NOT in the \n 'normative' \n reference group"),
  normexcld_f   = factor(c("HCAP - Included sample", "HCAP - Excluded sample"))
)

hrs16_cog %>%
  filter(!is.na(normexcld)) %>%
  mutate(normexcld_f = factor(normexcld, 
                              labels = c("HCAP - Included sample", "HCAP - Excluded sample"))) %>%
  ggplot(aes(x = F)) +
  geom_histogram() +
  geom_vline(data = F_mean, aes(xintercept = mean), color = "red") +
  facet_wrap(~normexcld_f, ncol=1) +
  hrbrthemes::theme_ipsum() 
# +
#   theme(plot.margin = unit(c(1, 1, 1, 10), "lines")) +
#   coord_cartesian(clip = "off", xlim=c(-3.5, 3)) +
#   geom_text(data = dat_text, aes(x = -5.1, y = 240, label=label), size=5.5)
```

::: {.absolute top=50 left=50  }
::: {style="font-size: .4em; "}
In the normative \
reference group
:::
:::

::: {.absolute top=255 left=50  }
::: {style="font-size: .4em; "}
**NOT** in the normative \
reference group
:::
:::

::: aside
::: {style="font-size: .8em; "}
Factor score estimate without adjustment, normalization, and standardization
:::
:::

------------------------------------------------------------------------

```{r}
#| fig-cap: Distribution of factor scores by HCAP normative reference status, including HRS sample
#| label: fig-hist-factor-scores-hrs
#| out-width: 600px
#| out-height: 500px
hrs16_cog <- readRDS(fs::path(r_objects_folder, "020_hrs16_cog.rds"))

F_mean <- hrs16_cog %>%
  mutate(
    f = factor(normexcld, labels = c("HCAP - Included sample", "HCAP - Excluded sample")),
    normexcld_f = forcats::fct_explicit_na(f, "Non-HCAP HRS")
  ) %>%
  group_by(normexcld_f) %>%
  summarize(mean = mean(F, na.rm=TRUE))

dat_text <- tibble(
  label = c("In the 'normative' \n reference group", "NOT in the \n 'normative' \n reference group", "NOT in \n HRS/HCAP"),
  normexcld_f   = factor(c("HCAP - Included sample", "HCAP - Excluded sample", "Non-HCAP HRS"))
)

hrs16_cog %>%
  mutate(
    f = factor(normexcld, labels = c("HCAP - Included sample", "HCAP - Excluded sample")),
    normexcld_f = forcats::fct_explicit_na(f, "Non-HCAP HRS")
  ) %>%
  ggplot(aes(x = F)) +
  geom_histogram() +
  geom_vline(data = F_mean, aes(xintercept = mean), color = "red") +
  facet_wrap(~normexcld_f, ncol=1) +
  hrbrthemes::theme_ipsum() 
# +
#   theme(plot.margin = unit(c(1, 1, 1, 10), "lines")) +
#   coord_cartesian(clip = "off", xlim=c(-3.5, 3)) +
#   geom_text(data = dat_text, aes(x = -5.1, y = 1500, label=label), size=5.5)
```

::: {.absolute top=50 left=50  }
::: {style="font-size: .4em; "}
In the normative \
reference group
:::
:::

::: {.absolute top=200 left=50  }
::: {style="font-size: .4em; "}
**NOT** in the normative \
reference group
:::
:::

::: {.absolute top=340 left=50  }
::: {style="font-size: .4em; "}
**NOT** in HRS/HCAP
:::
:::

::: aside
::: {style="font-size: .8em; "}
Factor score estimate without adjustment, normalization, and standardization
:::
:::

------------------------------------------------------------------------
```{r}
hrs16_cog <- readRDS(fs::path(r_objects_folder, "025_hrs16_cog.rds"))
hrs16_iadl <- readRDS(fs::path(r_objects_folder, "012_hrs16_iadl.rds"))
hrs16_func <- readRDS(fs::path(r_objects_folder, "013_hrs16_func.rds"))
hrshcap <- readRDS(fs::path(r_objects_folder, "014_hrshcap.rds"))

w051 <- haven::read_dta(here::here("Stata", "w051-preimputation.dta"))
w051 <- w051 %>%
  select(hhid, pn, Tgcp)
w073 <- haven::read_dta(here::here("Stata", "w073_hcapdx.dta"))
w073 <- w073 %>% 
  select(hhid, pn, n21, n22)

```

```{r}
hrs <- hrs16_cog %>%
  left_join(hrs16_iadl, by = c("HHID" = "HHID", "PN" = "PN")) %>%
  left_join(hrs16_func, by = c("HHID" = "HHID", "PN" = "PN")) %>%
  left_join(hrshcap, by = c("HHID" = "hhid", "PN" = "pn")) %>%
  left_join(w051, by = c("HHID" = "hhid", "PN" = "pn")) %>%
  left_join(w073, by = c("HHID" = "hhid", "PN" = "pn"))


```

```{r}
# Using the n=3496 sample
hcap <- hrs %>% 
  filter(!is.na(normexcld))

hcap <- hcap %>%
  mutate(CogImp = case_when(n21==0 & n22==0 ~ 0,
                            n21==0 & n22==1 ~ 1,
                            n21==1 ~ 2))

# QSPtools::checkvar(hcap, CogImp, n21, n22)
hcap <- hcap %>%
  labelled::set_variable_labels(CogImp = "Number of domains impaired") %>%
  labelled::set_value_labels(CogImp = c("No domains" = 0, "1 domain" = 1, "2+ domains" = 2))

# Filtering to the nonimputed sample (n=2993)
hcap <- hcap %>%
  filter(imputed_flag==1)

```

```{r}
#| fig-cap: "Cognitive factor score in HCAP vs HRS"
#| label: fig-scatter-fscore
hcap %>%
  ggplot(aes(x = Tgcp, y = TF)) +
    geom_point() +
    scale_x_continuous("HRS/HCAP GCP", limits = c(-30, 130)) +
    scale_y_continuous("HRS/Core GCP", limits = c(-30, 130)) +
    hrbrthemes::theme_ipsum()


```

::: aside
N = `r hcap %>% filter(!is.na(Tgcp) & !is.na(TF)) %>% nrow()`,  Correlation = `r cor(hcap$Tgcp, hcap$TF, "pairwise") %>% round(3)`
:::

------------------------------------------------------------------------

```{r}
#| fig-cap: "Bland-Altman plot of cognitive factor score in HCAP vs HRS"
#| label: fig-bland-altman-fscore

ba <- hcap %>%
  mutate(d = TF - Tgcp,
         avg = (Tgcp + TF)/2) 
ba_mean <- ba %>%
  summarize(m = mean(d, na.rm=TRUE),
            uci = m + 1.96*sd(d, na.rm=TRUE),
            lci = m - 1.96*sd(d, na.rm=TRUE)) %>%
  pivot_longer(cols = c(m, uci, lci), names_to = "p", values_to = "v")

ba %>%
  ggplot(aes(x = avg, y = d)) +
    geom_hline(data = ba_mean, aes(yintercept = v), color = "blue", linetype = 2) +
    geom_point() +
    scale_x_continuous("Average", limits = c(-10, 80)) +
    scale_y_continuous("Difference", limits = c(-60, 40)) +
    hrbrthemes::theme_ipsum()
```

::: aside
::: {style="font-size: .6em; line-height: .8em; "}
Limits of agreement (Reference Range for difference): `r ba_mean %>% filter(p == "lci") %>% pull(v) %>% round(3)` to `r ba_mean %>% filter(p == "uci") %>% pull(v) %>% round(3)` 

Mean difference: `r ba_mean %>% filter(p == "m") %>% pull(v) %>% round(3)` (CI `r (mean(ba$d, na.rm=T) + 1.96*sd(ba$d, na.rm=T)/sqrt(sum(!is.na(ba$d)))) %>% round(3)` to `r (mean(ba$d, na.rm=T) - 1.96*sd(ba$d, na.rm=T)/sqrt(sum(!is.na(ba$d)))) %>% round(3)`) 

Range : `r min(ba$avg, na.rm=TRUE) %>% round(3)` to `r max(ba$avg, na.rm=TRUE) %>% round(3)`
:::
:::
------------------------------------------------------------------------

```{r}
#| fig-cap: "Distribution of HCAP cognitive factor score by number of domains impaired"
#| label: fig-boxplot-hcap-fscore

hcap %>%
  ggplot(aes(y = Tgcp, x = factor(CogImp))) +
    geom_boxplot() +
    scale_x_discrete("Number of domains impaired") +
    scale_y_continuous("HRS/HCAP GCP (EAP)") +
    hrbrthemes::theme_ipsum()
```

::: aside
::: {style="font-size: .8em; "}
Number of domains impaired, based on full HRS/HCAP algorithm using 5 individual domains
:::
:::

------------------------------------------------------------------------

```{r}
#| fig-cap: "Distribution of HRS cognitive factor score by number of domains impaired"
#| label: fig-boxplot-hrs-fscore

hcap %>%
  ggplot(aes(y = TF, x = factor(CogImp))) +
    geom_boxplot() +
    scale_x_discrete("Number of domains impaired") +
    scale_y_continuous("HRS/Core GCP (EAP)") +
    hrbrthemes::theme_ipsum()
```
::: aside
::: {style="font-size: .8em; "}
Number of domains impaired, based on full HRS/HCAP algorithm using 5 individual domains
:::
:::

------------------------------------------------------------------------

```{r}
#| tbl-cap: "Distribution of the number of impaired domains in HCAP"
#| label: tbl-number-impaired-domains

hcap %>%
  select(CogImp) %>%
  labelled::to_factor() %>%
  gtsummary::tbl_summary() %>%
  gtsummary::as_gt() %>%
  gt::opt_stylize(6, color="gray") 
# %>%
#   gt::tab_options(
#     data_row.padding = gt::px(3)
#   )
```


::: aside
The plan for finding cut points on the HRS/Core adjusted, standardized, normalized factor score (here, TF) is to find the proportion in the HRS/HCAP with impairment in 2+ or exactly 1 of 5 domains impaired, and identifying cuts at the matching percentiles on the HRS/Core factor score (TF).
:::

::: {.absolute top=100 right=50  }
::: {style="font-size: .4em; "}
Number of domains impaired, based \
on full HRS/HCAP algorithm using 5 \
individual domains
:::
:::

```{r}
#| echo: true
quantile(hcap$TF, probs = c(.15, .35), na.rm=TRUE)

```


::: {.absolute top=400 left=50  }
::: {style="font-size: .4em; "}
Centiles of adjusted, normalized, standardized factor score in HRS/Core
:::
:::





------------------------------------------------------------------------

```{r}
hcap <- hcap %>%
  mutate(cog_imp_hrs = case_when(TF <36.0 ~ 2,
                             TF < 43.3 ~ 1,
                             !is.na(TF) ~ 0))
hcap <- hcap %>%
  labelled::set_variable_labels(cog_imp_hrs = "Level of cognitive impairment (HRS)") %>%
  labelled::set_value_labels(cog_imp_hrs = c("None" = 0, "Mild" = 1, "Severe" = 2))
k <- table(hcap$CogImp, hcap$cog_imp_hrs)

```

```{r}
#| tbl-cap: "Crosstab of number of domains impaired (HCAP) vs matched factor scores (HRS)"
#| label: tbl-cross-cog-impairment
hcap %>%
  labelled::to_factor() %>%
  gtsummary::tbl_cross(CogImp, cog_imp_hrs) %>%
  gtsummary::as_gt() %>%
  gt::opt_stylize(6, color="gray") 

# %>%
#   gt::tab_options(
#     data_row.padding = gt::px(4)
#   )
```


::: aside
Kappa with quadratic weights = `r psych::wkappa(k)$weighted.kappa %>% round(2)`
:::

::: {.absolute top=200 left=25  }
::: {style="font-size: .4em; "}
Number of domains impaired, \
based on full HRS/HCAP \
algorithm using 5 individual \
domains
:::
:::

::: {.absolute top=350 left=450  }
::: {style="font-size: .4em; "}
Based on matching centiles of adjusted, \
normalized, standardized factor score in \
HRS/Core
:::
:::


## Progress

-   [x] 1. Factor model for general cognition in HRS/Core (in R)

-   [x] 2. Adjustment, standardization and normalization (in R)

-   [x] 3. Equivalent cut point for identifying severe and moderate cognitive impairment to that used in HRS/HCAP algorithm

-   [ ] 4. Operationalize functional impairment in HRS/Core

-   [ ] 5. Run and compare algorithms

-   [ ] 6. Reporting

-------

```{r}
#| fig-cap: "HRS algorithm"
#| label: fig-hrs-algorithm2
#| out-height: "600px"
#| out-width: "700px"
knitr::include_graphics(here::here("Figures", "HRS-algorithm_2024-12-19.png"))
```

